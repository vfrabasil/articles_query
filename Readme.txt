# ---------------------------------------------------------------------------------------------------
Order of execution of scripts:
# ---------------------------------------------------------------------------------------------------


1) train_word2vec_model.py:
Run this script first to train the Word2Vec model using the text data from the files listed 
in articles_list.txt.
This will create a file named "word2vec_model.bin" containing the trained Word2Vec model.
>> python train_word2vec_model.py


2) chunk_and_store.py:
After training the Word2Vec model, run this script to chunk the text, embed it using the 
trained Word2Vec model, and store the embeddings along with the Faiss index for vector search.
>> python chunk_and_store.py

3) query.py:
Once the embeddings and Faiss index are stored, you can run this script for testing and querying. 
It prompts the user to enter a search query, embeds the query using the trained Word2Vec model, 
and performs vector search against the stored embeddings.
>> python query.py


# ---------------------------------------------------------------------------------------------------
files generated by the scripts:
# ---------------------------------------------------------------------------------------------------


article_embeddings.npy:
Purpose: This file contains the embeddings of text chunks from the processed articles. 
Each row corresponds to the embedding of a text chunk.
Usage: It is used as a data file to store the vector representations of the text chunks. 
During querying, the script loads this file to perform vector search against the user's input.

faiss_index.index:
Purpose: This file stores the Faiss index, which is a data structure optimized for 
fast similarity searches in high-dimensional spaces.
Usage: The Faiss index is built using the embeddings from article_embeddings.npy. 
During querying, the script loads this index to efficiently search for the most similar 
vectors to the user's input.

word2vec_model.bin:
Purpose: This file contains the trained Word2Vec model, which represents word 
embeddings learned from the provided text corpus.
Usage: The Word2Vec model is used to embed text chunks during the chunking process 
in chunk_and_store.py and to embed user queries during querying in query.py. 
It captures semantic relationships between words and helps in creating vector 
representations for chunks and queries.


# ---------------------------------------------------------------------------------------------------

